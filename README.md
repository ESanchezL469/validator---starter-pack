# Validator - Starter Pack

![Python](https://img.shields.io/badge/python-3.11-blue)
![License](https://img.shields.io/badge/license-MIT-green)

A robust Data Quality as a Service (DQaaS) platform that enables you to:

- Upload a CSV, Excel, JSON or Parquet dataset
- Automatically validate schema with [Pandera](https://pandera.readthedocs.io/)
- Enrich the dataset with business rules (e.g. age groups)
- Generate profiling reports with [YData Profiling](https://github.com/ydataai/ydata-profiling)
- Version and store validated data
- Expose everything via a FastAPI endpoint

---

## ðŸš€ Quickstart

### 1. Clone and install dependencies
```bash
git clone https://github.com/your-org/validator-starter-pack.git
cd validator-starter-pack
pip install -r requirements.txt
```

### 2. Set up environment variables
Create a `.env` file in the root directory:
```env
DATASETS_DIR=datasets
METADATA_DIR=metadatas
REPORTS_DIR=reports
PROFILES_DIR=profiles
API_PORT=8080
```

### 3. Run the API
```bash
make run
```

Visit http://localhost:8080/docs for the interactive API docs.

---

## ðŸ§ª Run Tests
```bash
make test
```

---

## ðŸ§± Project Structure
```
validator-starter-pack/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/             # FastAPI router + main app
â”‚   â”œâ”€â”€ core/            # DatasetValidator orchestrator
â”‚   â”œâ”€â”€ validators/      # Pandera schema definitions
â”‚   â”œâ”€â”€ enrichers/       # Data enrichment logic
â”‚   â”œâ”€â”€ reporters/       # Plain text report generator
â”‚   â”œâ”€â”€ profilers/       # ydata_profiling integration
â”‚   â”œâ”€â”€ metadata/        # Metadata generation & tracking
â”‚   â”œâ”€â”€ storage/         # File I/O, hashing, versioning
â”‚   â”œâ”€â”€ config.py        # .env config loader
â”‚   â””â”€â”€ setup.py         # Directory initializer
â”œâ”€â”€ datasets/            # Stored validated datasets (CSV/Parquet)
â”œâ”€â”€ profiles/            # Generated HTML profiling reports
â”œâ”€â”€ reports/             # Plaintext validation reports
â”œâ”€â”€ metadatas/           # JSON metadata files
â”œâ”€â”€ files/               # Example or temporary uploaded files
â”œâ”€â”€ tests/               # Unit tests
â”œâ”€â”€ .env                 # Environment variables
â”œâ”€â”€ run.py               # Startup script
â”œâ”€â”€ Makefile             # Development commands
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md            # This file
```

---

## ðŸ“Ž Sample CSV File
Save the following content in `files/sample.csv`:
```csv
id,name,email,age,created_at,is_active
1,Alice,alice@example.com,30,2023-01-01,True
2,Bob,bob@example.com,45,2022-06-15,False
3,Carol,carol@example.com,22,2024-03-10,True
```

Upload via Postman:
- Method: `POST`
- URL: `http://localhost:8080/validate/`
- Body: `form-data`
  - Key: `file`
  - Type: `File`
  - Value: select your `sample.csv`

---

## ðŸ“¡ API Endpoint

### `POST /validate/`
Upload a dataset and run validation pipeline.

#### Form-Data
- `file`: your dataset file (CSV, Excel, JSON, Parquet)

#### Example Response
```json
{
  "status": "success",
  "message": "File sample.csv has validate",
  "is_valid": true,
  "hash": "abc123...",
  "total_rows": 3,
  "errors": {},
  "report_url": "/report/abc123",
  "metadata_url": "/metadata/abc123",
  "profile_url": "/profile/abc123"
}
```

---

## ðŸ§° Makefile Commands

| Command       | Description                           |
|---------------|---------------------------------------|
| `make run`    | Launch the API server                 |
| `make test`   | Run unit tests with Pytest            |
| `make clean`  | Clean up `.pyc`, `__pycache__`, etc.  |

---

## ðŸ“œ License
MIT License